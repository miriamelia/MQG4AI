---
tags: [{Name: QG_Maintenance_(Lifecycle)}, {Intent: Overview}, {Applicability: GenericAILifecycle}, {Usage Example: default_highrisk}]
---

# QG Maintenance (Lifecycle)

The *Maintenance* section is not focus of our current contribution, and needs to be refined with further empirical experience, including dependencies with other AI quality management sections. The proposed structure is based on [An artificial intelligence life cycle: From conception to production](https://www.sciencedirect.com/science/article/pii/S2666389922000745?via%3Dihub): 

![](../../../imgs/Lifecycle/QG_Maintenance.png){width=800 height=}

During *Maintenance*, the intelligent system is in production, and needs to be continuously monitored, while compliance assessment necessitates a post-market monitoring strategy. Follow-up reviews can take place for high-risk applications. This stage is closely related with *Data*, *Development*, and *Deployment* to deliver model updates. The emerging field of [MLOps](https://arxiv.org/pdf/2303.04073) aims to automate this process. 

Information established during *Development* surrounding *Performance Metrics* is relevant at this stage, as well, and monitoring partly builds on the identified evaluation startegy. This includes specific occurrences, such as a detected shift in performance, or data distribution, which trigger a restart of the lifecycle iteration. 

### Overview Sub-QGs
Exemplary overview of process steps, based on [An artificial intelligence life cycle: From conception to production (CADAC)](https://www.sciencedirect.com/science/article/pii/S2666389922000745), ISO/IEC FDIS 5338:2023(E) on *Information Technology -- Artifical Intelligence -- AI system lifecycle processes*, and ISO/IEC 22989:2022 on *Information technology — Artificial intelligence — Artificial intelligence concepts and terminology*

![](../../../imgs/Lifecycle/Maintenance.png)
> This is only a proposition.

#### Operation
- additional considerations is collected, regarding the consumed computing power and memory usage, which need to be monitored, and evaluated, since they may impact further decision-making within the project, such as the frequency of training or the choice of the algorithm \cite[30]{ISO5338AIlifecycle}, linking to the development stage. (ISO5338, 30)
- In addition, "Operationalize using AI pipelines Also known as AIOps or MLOps, this stage is an adaptation of the highly effective DevOps software automation capabilities into AI model deployment." (CADAC, 9)
- "While the explicit goal of AI is to support/enable/augment human actions and decision making, hyperautomation attempts to takes this a step further by automating the actions and decision making within the boundaries of ethics and regulatory requirements." (CADAC, 9)

#### Monitoring
-  corresponds to \textit{continuous validation}, aiming to guarantee that "[...] AI models keeps performing satisfactorily, or to demonstrate performance of the AI model over time" (ISO5338, 29)
- "Continuous monitoring of end-user activity is critical to find out if and how the model is contributing toward organizational functions. The level of end-user activity depends on each use case and metrics can be drawn from adoption, questions, frequency of use, use/revision of documentation, feedback, and requests for features" (CADAC, 9) 
- "The AI system is monitored for both normal operation and also for incidents including unavailability, runtime failures or errors. These events are reported to relevant AI providers for action." (ISO22989, 39)
- The quality management process includes reporting and assessing of all incidents (system failures and data errors) (ISO5338, 31)
- "The main evaluation criteria are representative of the technology itself, diverse individuals in diverse settings utilizing the technology and value generated by the technology." (CADAC, 9) 
- "Risk management continuous improvement: Continuous validation should also be used to enable continuous improvement to risk management processes" (ISO22989, 40)
Overall, "Risk monitoring and review: Organizations should monitor AI systems during operation to assure and improve the quality and effectiveness of the risk management process"(ISO22989, 40)
- Detect deviations, such as model drift or model staleness, which may result in retraining the model or restarting the lifecycle (CADAC, 9)

#### Support
- "Users of the AI system are given any necessary support needed to successfully use the system." (ISO22989, 40)

#### Update
- "Update: AI system software, models and hardware can be updated to meet new requirements and to improve performance and reliability." (ISO22989, 40)