---
tags: [{Name: Accountability}, {Intent: Overview}, {Applicability: AIAct}, {Usage Example: default_highrisk}]
---

> Based on [ALTAI](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai)


### Definition Accountability
Mechanisms should be put in place to ensure responsibility and accountability for AI systems and their outcomes. Auditability, which enables the assessment of algorithms, data and design processes plays a key role therein, especially in critical applications. Moreover, adequate an accessible redress should be ensured.


#### Overview Requirements Accountability

##### Auditability
ALTAI:
> - Did you establish mechanisms that facilitate the AI system’s auditability (e.g. traceability of the development process, the sourcing of training data and the logging of the AI system’s processes, outcomes, positive and negative impact)?
>> MQG4AI's design is intended to support this process through lifecycle planning
> - Did you ensure that the AI system can be audited by independent third parties?

##### Risk Management
ALTAI:
> - Did you foresee any kind of external guidance or third-party auditing processes to oversee ethical concerns and accountability measures?
>   - Does the involvement of these third parties go beyond the development phase?
> - Did you organise risk training and, if so, does this also inform about the potential legal framework applicable to the AI system?
> - Did you consider establishing an AI ethics review board or a similar mechanism to discuss the overall accountability and ethics practices, including potential unclear grey areas?
> - Did you establish a process to discuss and continuously monitor and assess the AI system's adherence to this Assessment List for Trustworthy AI (ALTAI)?
>   - Does this process include identification and documentation of conflicts between the 6 aforementioned requirements or between different ethical principles and explanation of the 'trade-off' decisions made?
>   - Did you provide appropriate training to those involved in such a process and does this also cover the legal framework applicable to the AI system?
> - Did you establish a process for third parties (e.g. suppliers, end-users, subjects, distributors/vendors or workers) to report potential vulnerabilities, risks or biases in the AI system?
>   - Does this process foster revision of the risk management process?
> - For applications that can adversely affect individuals, have redress by design mechanisms been put in place?