---
tags: [{Name: HumanAgencyOversight}, {Intent: Overview}, {Applicability: AIAct}, {Usage Example: default_highrisk}]
---

> Based on [ALTAI](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai)

### Definition Human Agency and Oversight
AI systems should empower human beings, allowing them to make informed decisions and fostering their fundamental rights. At the same time, proper oversight mechanisms need to be ensured, which can be achieved through human-in-the-loop, human-on-the-loop, and human-in-command approaches.

#### Overview Requirements Human Agency and Oversight 

##### Human Agency and Autonomy
ALTAI:
> - Is the AI system designed to interact, guide or take decisions by human end-users that affect humans or society?
>   - Could the AI system generate confusion for some or all end-users or subjects on whether a decision, content, advice or outcome is the result of an algorithmic decision?
>   - Are end-users or other subjects adequately made aware that a decision, content, advice or outcome is the result of an algorithmic decision?
> - Could the AI system generate confusion for some or all end-users or subjects on whether they are interacting with a human or AI system?
>   - Are end-users or subjects informed that they are interacting with an AI system?
> - Could the AI system affect human autonomy by generating over-reliance by end-users?
>   - Did you put in place procedures to avoid that end-users over-rely on the AI system?
> - Could the AI system affect human autonomy by interfering with the end-user’s decision-making process in any other unintended and undesirable way?
>   - Did you put in place any procedure to avoid that the AI system inadvertently affects human autonomy?
> - Does the AI system simulate social interaction with or between end-users or subjects?
> - Does the AI system risk creating human attachment, stimulating addictive behaviour, or manipulating user behaviour? Depending on which risks are possible or likely, please answer the questions below:
>   - Did you take measures to deal with possible negative consequences for end-users or subjects in case they develop a disproportionate attachment to the AI System?
>   - Did you take measures to minimise the risk of addiction?
>   - Did you take measures to mitigate the risk of manipulation?

##### Human Oversight
ALTAI:
> - Please determine whether the AI system (choose as many as appropriate):
>   - Is a self-learning or autonomous system;
>   - Is overseen by a Human-in-the-Loop; 
    (capability for human intervention in every decision cycle of the system)
>   - Is overseen by a Human-on-the-Loop; 
    (capability for human intervention during the design cycle of the system and monitoring the system’s operation)
>   - Is overseen by a Human-in-Command. 
    (capability to oversee the overall activity of the AI system (including its broader economic, societal, legal and ethical impact) and the ability to decide when and how to use the AI system in any particular situation)
> - Have the humans (human-in-the-loop, human-on-the-loop, human-in-command) been given specific training on how to exercise oversight?
> - Did you establish any detection and response mechanisms for undesirable adverse effects of the AI system for the end-user or subject?
> - Did you ensure a ‘stop button’ or procedure to safely abort an operation when needed?
> - Did you take any specific oversight and control measures to reflect the self-learning or autonomous nature of the AI system?