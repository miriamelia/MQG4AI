---
tags: [{Name: Transparency}, {Intent: Overview}, {Applicability: AIAct}, {Usage Example: default_highrisk}]
---

> Based on [ALTAI](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai)


### Definition Transparency
The data, system and AI business models should be transparent. Traceability mechanisms can help achieving this. Moreover, AI systems and their decisions should be explained in a manner adapted to the stakeholder concerned. Humans need to be aware that they are interacting with an AI system, and must be informed of the systemâ€™s capabilities and limitations.


#### Overview Requirements Transparency 

##### Traceability

ALTAI:
> - Did you put in place measures that address the traceability of the AI system during its entire lifecycle?
>   - Did you put in place measures to continuously assess the quality of the input data to the AI system?
>   - Can you trace back which data was used by the AI system to make a certain decision(s) or recommendation(s)?
>   - Can you trace back which AI model or rules led to the decision(s) or recommendation(s) of the AI system?
>   - Did you put in place measures to continuously assess the quality of the output(s) of the AI system?
>        - Influenced by [Performance Evaluation Metrics](./../../../2_Lifecycle/2_Development/2_Model_Evaluation/PerformanceMetrics) and related with [Accuracy-related risk Unreliable Performance Metrics](./../2_TechnicalRobustnessSafety/Accuracy/UnreliablePerformanceMetrics.md)
>   - Did you put adequate logging practices in place to record the decision(s) or recommendation(s) of the AI system?

##### Explainability 

ALTAI:
> - Did you explain the decision(s) of the AI system to the [users](./../../../1_System/Stakeholder/Stakeholder.md#2-ai-users)?
> - Do you continuously survey the [users](./../../../1_System/Stakeholder/Stakeholder.md#2-ai-users) if they understand the decision(s) of the AI system?

Additional Questions:
> - Did you apply [methods](./../../../1_System/AI_System.md#ai-technique---lifecycle-implementation) to explain the model output?
> - Did you validate the applied [explainability techniques](./../../../1_System/AI_System.md#ai-technique---lifecycle-implementation)?


###### Communication

ALTAI:
> - In cases of interactive AI systems (e.g., chatbots, robo-lawyers), do you communicate to users that they are interacting with an AI system instead of a human?
> - Did you establish mechanisms to inform users about the purpose, criteria and limitations of the decision(s) generated by the AI system?
>    - Did you communicate the benefits of the AI system to users?
>    - Did you communicate the technical limitations and potential risks of the AI system to users, such as its level of accuracy and/ or error rates?
>    - Did you provide appropriate training material and disclaimers to users on how to adequately use the AI system?

